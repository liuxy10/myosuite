{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyoSuite:> Registering Myo Envs\n"
     ]
    }
   ],
   "source": [
    "from myosuite.utils import gym\n",
    "import skvideo.io\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SAR_tutorial_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# imports for SAR\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSAR_tutorial_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'SAR_tutorial_utils'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "def show_video(video_path, video_width = 400):\n",
    "\n",
    "  video_file = open(video_path, \"r+b\").read()\n",
    "\n",
    "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
    "  return HTML(f\"\"\"<video autoplay width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: failed to open /dev/dri/renderD128: Permission denied\n",
      "\n",
      "libEGL warning: failed to open /dev/dri/renderD128: Permission denied\n",
      "\n",
      "libEGL warning: NEEDS EXTENSION: falling back to kms_swrast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m    MyoSuite: A contact-rich simulation suite for musculoskeletal motor control\n",
      "        Vittorio Caggiano, Huawei Wang, Guillaume Durandau, Massimo Sartori, Vikash Kumar\n",
      "        L4DC-2019 | https://sites.google.com/view/myosuite\n",
      "    \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('myoLegHillyTerrainWalk-v0')\n",
    "\n",
    "env.reset();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install git+https://github.com/liuxy10/mjrl.git\n",
    "# !pip install 'gym==0.16.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m myosuite.tests.test_myo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported environment format\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     14\u001b[0m rl_step_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m---> 15\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43mGymEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# e = env\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# e = GymEnv('myoElbowPose1D6MRandom-v0')\u001b[39;00m\n\u001b[1;32m     19\u001b[0m policy \u001b[38;5;241m=\u001b[39m MLP(e\u001b[38;5;241m.\u001b[39mspec, hidden_sizes\u001b[38;5;241m=\u001b[39mpolicy_size, seed\u001b[38;5;241m=\u001b[39mseed, init_log_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.25\u001b[39m, min_log_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myosuite/lib/python3.8/site-packages/mjrl/utils/gym_env.py:30\u001b[0m, in \u001b[0;36mGymEnv.__init__\u001b[0;34m(self, env, env_kwargs, obs_mask, act_repeat, *args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported environment format\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;241m=\u001b[39m env\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_id \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mid\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from mjrl.utils.gym_env import GymEnv\n",
    "from mjrl.policies.gaussian_mlp import MLP\n",
    "from mjrl.baselines.mlp_baseline import MLPBaseline\n",
    "from mjrl.algos.npg_cg import NPG\n",
    "from mjrl.utils.train_agent import train_agent\n",
    "import myosuite\n",
    "\n",
    "policy_size = (32, 32)\n",
    "vf_hidden_size = (128, 128)\n",
    "seed = 123\n",
    "rl_step_size = 0.1\n",
    "e = GymEnv(env)\n",
    "# e = env\n",
    "# e = GymEnv('myoElbowPose1D6MRandom-v0')\n",
    "\n",
    "policy = MLP(e.spec, hidden_sizes=policy_size, seed=seed, init_log_std=-0.25, min_log_std=-1.0)\n",
    "\n",
    "baseline = MLPBaseline(e.spec, reg_coef=1e-3, batch_size=64, hidden_sizes=vf_hidden_size, \\\n",
    "                    epochs=2, learn_rate=1e-3)\n",
    "\n",
    "agent = NPG(e, policy, baseline, normalized_step_size=rl_step_size, \\\n",
    "            seed=seed, save_logs=True)\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"Starting policy learning\")\n",
    "print(\"========================================\")\n",
    "\n",
    "train_agent(job_name='.',\n",
    "            agent=agent,\n",
    "            seed=seed,\n",
    "            niter=200,\n",
    "            gamma=0.995,\n",
    "            gae_lambda=0.97,\n",
    "            num_cpu=8,\n",
    "            sample_mode=\"trajectories\",\n",
    "            num_traj=96,\n",
    "            num_samples=0,\n",
    "            save_freq=100,\n",
    "            evaluation_rollouts=10)\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"Job Finished.\")\n",
    "print(\"========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from mjrl.utils.gym_env import GymEnv\n",
    "from mjrl.policies.gaussian_mlp import MLP\n",
    "from mjrl.baselines.mlp_baseline import MLPBaseline\n",
    "from mjrl.algos.npg_cg import NPG\n",
    "from mjrl.utils.train_agent import train_agent\n",
    "import myosuite\n",
    "\n",
    "policy_size = (32, 32)\n",
    "vf_hidden_size = (128, 128)\n",
    "seed = 123\n",
    "rl_step_size = 0.1\n",
    "e = GymEnv(env)\n",
    "# e = env\n",
    "# e = GymEnv('myoElbowPose1D6MRandom-v0')\n",
    "\n",
    "policy = MLP(e.spec, hidden_sizes=policy_size, seed=seed, init_log_std=-0.25, min_log_std=-1.0)\n",
    "\n",
    "baseline = MLPBaseline(e.spec, reg_coef=1e-3, batch_size=64, hidden_sizes=vf_hidden_size, \\\n",
    "                    epochs=2, learn_rate=1e-3)\n",
    "\n",
    "agent = NPG(e, policy, baseline, normalized_step_size=rl_step_size, \\\n",
    "            seed=seed, save_logs=True)\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"Starting policy learning\")\n",
    "print(\"========================================\")\n",
    "\n",
    "train_agent(job_name='.',\n",
    "            agent=agent,\n",
    "            seed=seed,\n",
    "            niter=200,\n",
    "            gamma=0.995,\n",
    "            gae_lambda=0.97,\n",
    "            num_cpu=8,\n",
    "            sample_mode=\"trajectories\",\n",
    "            num_traj=96,\n",
    "            num_samples=0,\n",
    "            save_freq=100,\n",
    "            evaluation_rollouts=10)\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"Job Finished.\")\n",
    "print(\"========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = \"iterations/best_policy.pickle\"\n",
    "\n",
    "import pickle\n",
    "pi = pickle.load(open(policy, 'rb'))\n",
    "\n",
    "AngleSequence = [60, 30, 30, 60, 80, 80, 60, 30, 80, 30, 80, 60]\n",
    "env.reset()\n",
    "frames = []\n",
    "for ep in range(len(AngleSequence)):\n",
    "    print(\"Ep {} of {} testing angle {}\".format(ep, len(AngleSequence), AngleSequence[ep]))\n",
    "    env.unwrapped.target_jnt_value = [np.deg2rad(AngleSequence[int(ep)])]\n",
    "    env.unwrapped.target_type = 'fixed'\n",
    "    env.unwrapped.weight_range=(0,0)\n",
    "    env.unwrapped.update_target()\n",
    "    for _ in range(40):\n",
    "        frame = env.sim.render(width=400, height=400,mode='offscreen', camera_name=None)\n",
    "        frames.append(frame[::-1,:,:])\n",
    "        o = env.get_obs()\n",
    "        a = pi.get_action(o)[0]\n",
    "        next_o, r, done, *_, ifo = env.step(a) # take an action based on the current observation\n",
    "env.close()\n",
    "\n",
    "os.makedirs('videos', exist_ok=True)\n",
    "# make a local copy\n",
    "skvideo.io.vwrite('videos/arm.mp4', np.asarray(frames),outputdict={\"-pix_fmt\": \"yuv420p\"})\n",
    "show_video('videos/arm.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
